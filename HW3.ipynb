{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogRegSGD:\n",
    "    def __init__(self, fixed_learning_rate = 0.01, batch_size = 10, max_iters = 10000):\n",
    "        self.learning_rate = fixed_learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.max_iterations = max_iters\n",
    "        self.weights = None  \n",
    "\n",
    "    def compute_loss(self, preds, t):\n",
    "        e = 1e-9\n",
    "        return -np.mean(t * np.log(preds + e) + (1 - t) * np.log(1 - preds + e))\n",
    "    \n",
    "    def sigmoid(self, s):\n",
    "        return 1 / (1 + np.exp(-s))\n",
    "\n",
    "    def train(self, features, labels):\n",
    "        num_samples, num_features = features.shape\n",
    "        self.weights = np.random.randn(num_features) * 0.001  \n",
    "\n",
    "        for iteration in range(self.max_iterations):\n",
    "            shuffled_indices = np.random.permutation(num_samples)\n",
    "            shuffled_features = features[shuffled_indices]\n",
    "            shuffled_labels = labels[shuffled_indices]\n",
    "\n",
    "            for batch_start in range(0, num_samples, self.batch_size):\n",
    "                batch_end = batch_start + self.batch_size\n",
    "                X_batch = shuffled_features[batch_start:batch_end]\n",
    "                y_batch = shuffled_labels[batch_start:batch_end]\n",
    "\n",
    "                predictions = self.sigmoid(np.dot(X_batch, self.weights)).reshape(-1)\n",
    "                gradient = np.dot(X_batch.T, (predictions - y_batch)) / len(y_batch)\n",
    "                self.weights -= self.learning_rate * gradient\n",
    "            full_predictions = self.sigmoid(np.dot(features, self.weights))\n",
    "            loss = self.compute_loss(full_predictions, labels)\n",
    "\n",
    "            if iteration % 100 == 0:\n",
    "                print(f\"Iteration {iteration}, Loss: {loss:.4f}\")\n",
    "\n",
    "    def predict_probabilities(self, features):\n",
    "        return self.sigmoid(np.dot(features, self.weights))\n",
    "\n",
    "    def predict(self, features):\n",
    "        return (self.predict_probabilities(features) >= 0.5).astype(int)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 186, 1: 297}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_breast_cancer()\n",
    "X = data.data  \n",
    "y = data.target \n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size = 0.3, random_state = 42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size = 0.5, random_state = 42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "unique, counts = np.unique(np.concatenate((y_train, y_val)), return_counts = True)\n",
    "class_size = dict(zip(unique, counts))\n",
    "class_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Loss: 0.4840\n",
      "Iteration 100, Loss: 0.0990\n",
      "Iteration 200, Loss: 0.0825\n",
      "Iteration 300, Loss: 0.0748\n",
      "Iteration 400, Loss: 0.0701\n",
      "Iteration 500, Loss: 0.0667\n",
      "Iteration 600, Loss: 0.0641\n",
      "Iteration 700, Loss: 0.0621\n",
      "Iteration 800, Loss: 0.0605\n",
      "Iteration 900, Loss: 0.0591\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9883720930232558, 1.0, 0.9833333333333333, 0.9915966386554621)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogRegSGD(fixed_learning_rate = 0.01, batch_size = 24, max_iters = 1000)\n",
    "model.train(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "accuracy, precision, recall, f1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model correctly classified 98.84% of test samples with 100% precision, which means indicates that when the model created no false positives. The model also had 98.33% recall which shows that the model identified 98.33% of all actual positive cases. The loss decreased from 0.4830 to 0.0591 over 1000 iterations, showing effective learning by the model. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
